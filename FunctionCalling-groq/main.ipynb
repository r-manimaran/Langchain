{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function calling using OpenSource LLM model (llama-3) using groq and Langchain\n",
    "1. Load LLMs\n",
    "2. Define Tools ( in langchain functions are refered as tools )\n",
    "3. Link Tools with LLMs\n",
    "4. Use LLM with Tools\n",
    "5. Create independent Decision Taking Agent\n",
    "\n",
    "**Installation**\n",
    "- Install the necessary packages. I have used Poetry to create virtual env and manage dependencies."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "import os\n",
    "load_dotenv(find_dotenv())\n",
    "groq_api_key = os.environ.get(\"GROQ_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "llama3 = ChatOpenAI(model=\"llama3-8b-8192\",\n",
    "                    base_url=\"https://api.groq.com/openai/v1\",\n",
    "                    api_key = groq_api_key,\n",
    "                    temperature=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test the llm with a invoke\n",
    "ai_msg = llama3.invoke(\"Explain about ResultPattern in .Net in four or 5 lines\")\n",
    "ai_msg = ai_msg.content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'In .NET, `ResultPattern` is a feature introduced in C# 9.0 that allows you to handle exceptions and errors in a more concise and expressive way. It provides a way to specify a pattern to match against the result of an expression, and execute a block of code if the pattern matches. This can be used to simplify error handling and make code more readable.'"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ai_msg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.Define Tools ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import tool\n",
    "\n",
    "@tool\n",
    "def add(a: int, b: int) -> int:\n",
    "    \"\"\"Add two integers and return the result.\n",
    "       Args:\n",
    "         a: The first integer to add.\n",
    "         b: The second integer to add.\n",
    "       Returns:\n",
    "         The sum of the two integers, or None if either input is invalid.\n",
    "    \"\"\"\n",
    "    return a + b\n",
    "\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"Multiply two integers and return the result.\n",
    "       Args:\n",
    "         a: The first integer to multiply.\n",
    "         b: The second integer to multiply.\n",
    "       Returns:\n",
    "         The product of the two integers, or None if either input is invalid.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "tools = [add, multiply]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Link tools to LLM "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'add',\n",
       "  'args': {'a': 12, 'b': 12},\n",
       "  'id': 'call_e51v',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'multiply',\n",
       "  'args': {'a': 24, 'b': 10},\n",
       "  'id': 'call_36vr',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_with_tools = llama3.bind_tools(tools)\n",
    "result = llama3_with_tools.invoke(\"What is (12+12) x 10 ?\")\n",
    "result.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'type': 'function',\n",
       "  'function': {'name': 'add',\n",
       "   'description': 'Add two integers and return the result.\\n       Args:\\n         a: The first integer to add.\\n         b: The second integer to add.\\n       Returns:\\n         The sum of the two integers, or None if either input is invalid.',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}},\n",
       " {'type': 'function',\n",
       "  'function': {'name': 'multiply',\n",
       "   'description': 'Multiply two integers and return the result.\\n       Args:\\n         a: The first integer to multiply.\\n         b: The second integer to multiply.\\n       Returns:\\n         The product of the two integers, or None if either input is invalid.',\n",
       "   'parameters': {'properties': {'a': {'type': 'integer'},\n",
       "     'b': {'type': 'integer'}},\n",
       "    'required': ['a', 'b'],\n",
       "    'type': 'object'}}}]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llama3_with_tools.to_json()['kwargs']['kwargs']['tools']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_e51v', 'function': {'arguments': '{\"a\":12,\"b\":12}', 'name': 'add'}, 'type': 'function'}, {'id': 'call_36vr', 'function': {'arguments': '{\"a\":24,\"b\":10}', 'name': 'multiply'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2305, 'total_tokens': 2430, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': -0.551996454, 'prompt_time': 0.362100982, 'completion_time': 0.104166667, 'total_time': 0.466267649}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-c43c3e5f-8f7b-4fea-8bee-03654b6d2fdc-0', tool_calls=[{'name': 'add', 'args': {'a': 12, 'b': 12}, 'id': 'call_e51v', 'type': 'tool_call'}, {'name': 'multiply', 'args': {'a': 24, 'b': 10}, 'id': 'call_36vr', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2305, 'output_tokens': 125, 'total_tokens': 2430, 'input_token_details': {}, 'output_token_details': {}})"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Use LLM with Tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[HumanMessage(content='What is (12*10)+20?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='', additional_kwargs={'tool_calls': [{'id': 'call_z1g3', 'function': {'arguments': '{\"a\":12,\"b\":10}', 'name': 'multiply'}, 'type': 'function'}, {'id': 'call_fmxs', 'function': {'arguments': '{\"a\":120,\"b\":20}', 'name': 'add'}, 'type': 'function'}], 'refusal': None}, response_metadata={'token_usage': {'completion_tokens': 125, 'prompt_tokens': 2301, 'total_tokens': 2426, 'completion_tokens_details': None, 'prompt_tokens_details': None, 'queue_time': -0.474444328, 'prompt_time': 0.317781362, 'completion_time': 0.104166667, 'total_time': 0.421948029}, 'model_name': 'llama3-8b-8192', 'system_fingerprint': 'fp_6a6771ae9c', 'finish_reason': 'tool_calls', 'logprobs': None}, id='run-cefed851-3838-4696-83d0-aacb5b603576-0', tool_calls=[{'name': 'multiply', 'args': {'a': 12, 'b': 10}, 'id': 'call_z1g3', 'type': 'tool_call'}, {'name': 'add', 'args': {'a': 120, 'b': 20}, 'id': 'call_fmxs', 'type': 'tool_call'}], usage_metadata={'input_tokens': 2301, 'output_tokens': 125, 'total_tokens': 2426, 'input_token_details': {}, 'output_token_details': {}}),\n",
       " ToolMessage(content='120', tool_call_id='call_z1g3'),\n",
       " ToolMessage(content='140', tool_call_id='call_fmxs')]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, ToolMessage\n",
    "query = \"What is (12*10)+20?\"\n",
    "messages = [HumanMessage(query)]\n",
    "ai_msg = llama3_with_tools.invoke(query)\n",
    "messages.append(ai_msg)\n",
    "\n",
    "# manually we are defining and calling the tools\n",
    "for tool_call in ai_msg.tool_calls:\n",
    "    selected_tool = {\"add\":add,\"multiply\":multiply}[tool_call[\"name\"].lower()]\n",
    "    tool_output = selected_tool.invoke(tool_call[\"args\"])\n",
    "    messages.append(ToolMessage(\n",
    "        tool_call_id=tool_call[\"id\"],\n",
    "        content=str(tool_output)\n",
    "    ))\n",
    "messages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "So, the calculation is:\n",
      "\n",
      "(12*10) = 120\n",
      "+ 20 = 140\n",
      "\n",
      "So, the final answer is: 140\n"
     ]
    }
   ],
   "source": [
    "final_response = llama3.invoke(messages)\n",
    "print(final_response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Create Independent Decision Taking Agent\n",
    "- Use Agent to automate the decision making to select the required tools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.agents import AgentExecutor, create_tool_calling_agent, create_openai_tools_agent\n",
    "from langchain_openai import ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
    "\n",
    "prompt = ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\", \"You are a helpful assistant. You may not need to use tools for every query- the user may just want to chat!\"),\n",
    "        MessagesPlaceholder(variable_name=\"messages\"),\n",
    "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
    "    ]\n",
    ")\n",
    "llama3 = ChatOpenAI(model=\"llama3-70b-8192\", \n",
    "                    base_url=\"https://api.groq.com/openai/v1\",\n",
    "                    api_key = groq_api_key,\n",
    "                    temperature=0.0)\n",
    "agent = create_tool_calling_agent(llama3, tools, prompt)\n",
    "agent_executor = AgentExecutor(agent=agent, tools=tools, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 10, 'b': 15}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m25\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 25, 'b': 4}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m100\u001b[0m\u001b[32;1m\u001b[1;3mThe result is 100.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 10 and 15 and then multiply by 4', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The result is 100.'}"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "agent_executor.invoke({\"messages\":[HumanMessage(content=\"Add 10 and 15 and then multiply by 4\")]})\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 3, 'b': 12}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m36\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 34, 'b': 89}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m123\u001b[0m\u001b[32;1m\u001b[1;3mThe answer to 3*12 is 36 and the answer to 34+89 is 123.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='What is 3*12? Also what is 34+89?', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The answer to 3*12 is 36 and the answer to 34+89 is 123.'}"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\":[HumanMessage(content=\"What is 3*12? Also what is 34+89?\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new AgentExecutor chain...\u001b[0m\n",
      "\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `add` with `{'a': 121, 'b': 6}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[36;1m\u001b[1;3m127\u001b[0m\u001b[32;1m\u001b[1;3m\n",
      "Invoking: `multiply` with `{'a': 127, 'b': 2}`\n",
      "\n",
      "\n",
      "\u001b[0m\u001b[33;1m\u001b[1;3m254\u001b[0m\u001b[32;1m\u001b[1;3mThe final answer is 254.\u001b[0m\n",
      "\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'messages': [HumanMessage(content='Add 121 to 6 then multiply by 2', additional_kwargs={}, response_metadata={})],\n",
       " 'output': 'The final answer is 254.'}"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "agent_executor.invoke({\"messages\":[HumanMessage(content=\"Add 121 to 6 then multiply by 2\")]})\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
