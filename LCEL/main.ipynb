{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.output_parsers  import StrOutputParser\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_openai import ChatOpenAI\n",
    "from dotenv import load_dotenv\n",
    "\n",
    "load_dotenv()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Why did the artificial intelligence break up with its robot girlfriend? It couldn't handle her constant buffering.\""
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prompt = ChatPromptTemplate.from_template(\"tell me a short joke about {topic}\")\n",
    "model = ChatOpenAI()\n",
    "output_parser = StrOutputParser()\n",
    "\n",
    "chain = prompt | model | output_parser\n",
    "chain.invoke({\"topic\": \"AI\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "messages=[HumanMessage(content='tell me a short joke about AI')]\n"
     ]
    }
   ],
   "source": [
    "print(prompt.invoke({\"topic\":\"AI\"}))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content='Why did the AI break up with its computer program girlfriend? \\nBecause she had too many bugs in her code!', response_metadata={'token_usage': {'completion_tokens': 23, 'prompt_tokens': 14, 'total_tokens': 37}, 'model_name': 'gpt-3.5-turbo-0125', 'system_fingerprint': None, 'finish_reason': 'stop', 'logprobs': None}, id='run-534361ce-a166-469d-8749-574591501f1b-0', usage_metadata={'input_tokens': 14, 'output_tokens': 23, 'total_tokens': 37})"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages.human import HumanMessage\n",
    "messages =[HumanMessage(content='tell me a short joke about AI')]\n",
    "model.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from abc import ABC, abstractmethod\n",
    "\n",
    "class CRunnable(ABC):\n",
    "    def __init__(self):\n",
    "        self.next = None\n",
    "\n",
    "    @abstractmethod\n",
    "    def process(self,data):\n",
    "        \"\"\"\n",
    "        This method should be overridden by subclasses to implement the specific processing logic.\n",
    "        \"\"\"\n",
    "    def invoke(self,data):\n",
    "        processed_data = self.process(data)\n",
    "        if self.next is not None:\n",
    "            self.next.invoke(processed_data)\n",
    "        \n",
    "        return processed_data\n",
    "    \n",
    "    def __or__(self, other) :\n",
    "        return CRunnableSequence(self, other)   \n",
    "    \n",
    "class CRunnableSequence(CRunnable):\n",
    "    def __init__(self, first,second):\n",
    "        super().__init__()\n",
    "        self.first = first\n",
    "        self.second = second\n",
    "        \n",
    "    def process(self, data):\n",
    "        return data\n",
    "    \n",
    "    def invoke(self, data):\n",
    "        first_result = self.first.invoke(data)\n",
    "        return self.second.invoke(first_result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class AddTen(CRunnable):\n",
    "    def process(self,data):\n",
    "        print(\"AddTen\", data)\n",
    "        return data + 10\n",
    "    \n",
    "class MultiplyByTwo(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"MultiplyByTwo\", data)\n",
    "        return data * 2\n",
    "    \n",
    "class ConvertToString(CRunnable):\n",
    "    def process(self, data):\n",
    "        print(\"ConvertToString\", data)\n",
    "        return f'Result:{data}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a=AddTen()\n",
    "b=MultiplyByTwo()\n",
    "c=ConvertToString()\n",
    "\n",
    "chain = a|b|c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AddTen 10\n",
      "MultiplyByTwo 20\n",
      "ConvertToString 40\n",
      "Result:40\n"
     ]
    }
   ],
   "source": [
    "result = chain.invoke(10)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MultiplyByTwo 2\n",
      "AddTen 4\n",
      "ConvertToString 14\n",
      "Result:14\n"
     ]
    }
   ],
   "source": [
    "# Now change the sequence and check the chain\n",
    "chain = b|a|c\n",
    "result = chain.invoke(2)\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Runnables from Langchain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.runnables import RunnablePassthrough, RunnableLambda, RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Hello'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#RunnablePassthrough just pass the input and does nothing\n",
    "#it is used with other Runnable to create a pipeline\n",
    "\n",
    "chain = RunnablePassthrough() | RunnablePassthrough() | RunnablePassthrough()\n",
    "chain.invoke(\"Hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# custom function to convert string to upper\n",
    "def string_to_upper(input_string):\n",
    "    \"\"\"\n",
    "    Converts a given string to uppercase.\n",
    "\n",
    "    Args:\n",
    "        input_string (str): The string to be converted to uppercase.\n",
    "\n",
    "    Returns:\n",
    "        str: The uppercase version of the input string.\n",
    "    \"\"\"\n",
    "    return input_string.upper()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HELLO WORLD'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnablePassthrough() | RunnableLambda(string_to_upper) | RunnablePassthrough()\n",
    "chain.invoke(\"hello world\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RunnableParallel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain = RunnableParallel({\"x\":RunnablePassthrough(),\"y\":RunnablePassthrough()})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'hello', 'y': 'hello'}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke(\"hello\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input1': 'Hello', 'input2': 'World'},\n",
       " 'y': {'input1': 'Hello', 'input2': 'World'}}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input1\":\"Hello\",\"input2\":\"World\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': {'input1': 1, 'input2': 2}, 'y': 2}"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "chain = RunnableParallel({\"x\":RunnablePassthrough(),\"y\":lambda z:z[\"input2\"]})\n",
    "chain.invoke({\"input1\":1, \"input2\":2})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Nested Chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_keys_to_uppercase(input:dict):\n",
    "    output = input.get(\"input\",\"not found\").upper()\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'NOT FOUND', 'y': 'world'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain = RunnableParallel({\"x\":RunnablePassthrough() | RunnableLambda(find_keys_to_uppercase),\"y\":lambda z:z[\"input2\"]})\n",
    "chain.invoke({\"input1\":\"hello\", \"input2\":\"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'x': 'HELLO', 'y': 'world'}"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.invoke({\"input\":\"hello\", \"input2\":\"world\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Using FAISS with Lambda\n",
    "\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from langchain_openai import OpenAIEmbeddings, ChatOpenAI\n",
    "from langchain_core.prompts import ChatPromptTemplate\n",
    "from langchain_core.output_parsers import StrOutputParser\n",
    "from langchain_core.runnables import RunnableLambda, RunnablePassthrough\n",
    "from dotenv import load_dotenv,find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorStoreFaiss  = FAISS.from_texts(['Gooseberry is better than Apple','Dog loves bones'],\n",
    "                                     embedding=OpenAIEmbeddings()\n",
    "                                     )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "retriever = vectorStoreFaiss.as_retriever()\n",
    "template = \"\"\"Answer based on context:\\n\\n{context}\\n\\nQuestion: {question}\\n\\nAnswer:\"\"\"\n",
    "prompt = ChatPromptTemplate.from_template(template=template)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_docs(docs):\n",
    "    return \"\\n\\n\".join(doc.page_content for doc in docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "rag_chain = (\n",
    "    {\"context\":retriever | format_docs, \"question\":RunnablePassthrough()}\n",
    "    | prompt\n",
    "    | ChatOpenAI()\n",
    "    | StrOutputParser()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Gooseberry'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rag_chain.invoke(\"Which is better than Apple?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
