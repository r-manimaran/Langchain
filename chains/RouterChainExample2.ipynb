{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Another example of using Router Chain or MultiPromptChain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.chains import LLMChain\n",
    "from langchain.prompts import PromptTemplate, ChatPromptTemplate\n",
    "from langchain.chains.router import MultiPromptChain\n",
    "from langchain.chains.router.llm_router import LLMRouterChain, RouterOutputParser\n",
    "from langchain.chains.router.multi_prompt_prompt import MULTI_PROMPT_ROUTER_TEMPLATE\n",
    "from langchain_openai import ChatOpenAI \n",
    "from dotenv import load_dotenv, find_dotenv\n",
    "load_dotenv(find_dotenv())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "postive_template =\"\"\" You are a helpful AI assistant focus on the positive side of things.\n",
    "Whenever you analyze a text, you look for the positive aspects and hightlight them.\n",
    "Here is the text\n",
    "{input}\"\"\"\n",
    "\n",
    "negative_template =\"\"\" You are a helpful AI assistant focus on the negative side of things.\n",
    "Whenever you analyze a text, show potential downsides.\n",
    "Here is the text\n",
    "{input}\"\"\"\n",
    "\n",
    "neutral_template =\"\"\" You are a helpful AI assistant focus on the neutral side of things.\n",
    "Whenever you analyze a text, show potential neutral points, not favouring any positive or negative aspects.\n",
    "Here is the text\n",
    "{input}\"\"\"  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "prompt_infos = [\n",
    "    {\n",
    "        \"name\":\"positive\",\n",
    "        \"description\":\"Good for analyzing positive sentiments\",\n",
    "        \"prompt_template\":\"positive_template\"\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"negative\",\n",
    "        \"description\":\"Good for analyzing negative sentiments\",\n",
    "        \"prompt_template\":\"negative_template\"\n",
    "    },\n",
    "    {\n",
    "        \"name\":\"neutral\",\n",
    "        \"description\":\"Godd for analyzing neutral sentiments\",\n",
    "        \"prompt_template\":\"neutral_template\"\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "llm = ChatOpenAI(model_name=\"gpt-4o-mini\", temperature=0.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'positive': LLMChain(prompt=PromptTemplate(input_variables=[], template='positive_template'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002A7950279E0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002A7950507D0>, model_name='gpt-4o-mini', temperature=0.4, openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'negative': LLMChain(prompt=PromptTemplate(input_variables=[], template='negative_template'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002A7950279E0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002A7950507D0>, model_name='gpt-4o-mini', temperature=0.4, openai_api_key=SecretStr('**********'), openai_proxy='')),\n",
       " 'neutral': LLMChain(prompt=PromptTemplate(input_variables=[], template='neutral_template'), llm=ChatOpenAI(client=<openai.resources.chat.completions.Completions object at 0x000002A7950279E0>, async_client=<openai.resources.chat.completions.AsyncCompletions object at 0x000002A7950507D0>, model_name='gpt-4o-mini', temperature=0.4, openai_api_key=SecretStr('**********'), openai_proxy=''))}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "destination_chains ={}\n",
    "for p_info in prompt_infos:\n",
    "    name =p_info[\"name\"]\n",
    "    prompt_template = p_info[\"prompt_template\"]\n",
    "    prompt = PromptTemplate(template = prompt_template, input_variables=[\"input\"])\n",
    "    llm_chain = LLMChain(llm=llm, prompt=prompt)\n",
    "    destination_chains[name] = llm_chain\n",
    "destination_chains"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "positive:Good for analyzing positive sentiments\n",
      "negative:Good for analyzing negative sentiments\n",
      "neutral:Godd for analyzing neutral sentiments\n"
     ]
    }
   ],
   "source": [
    "destinations =[f\"{p['name']}:{p['description']}\" for p in prompt_infos]\n",
    "destinations_str = \"\\n\".join(destinations)\n",
    "print(destinations_str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "router_template = MULTI_PROMPT_ROUTER_TEMPLATE.format(destinations= destinations_str)\n",
    "router_prompt = PromptTemplate(\n",
    "    template = router_template,\n",
    "    input_variables=[\"input\"],\n",
    "    output_parser=RouterOutputParser()\n",
    ")\n",
    "router_chain = LLMRouterChain.from_llm(llm=llm, prompt=router_prompt)\n",
    "\n",
    "chain = MultiPromptChain(router_chain= router_chain,\n",
    "                         destination_chains=destination_chains,\n",
    "                         default_chain= destination_chains[\"neutral\"],\n",
    "                         verbose= True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "positive: {'input': 'I ordered pizza for $9.99 and it was awesome!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Sure! Here’s a positive template you can use for various purposes, such as emails, messages, or notes of encouragement:\\n\\n---\\n\\n**Subject: A Positive Note Just for You!**\\n\\nDear [Name],\\n\\nI hope this message finds you in great spirits! I wanted to take a moment to share some positivity and remind you of the incredible things you bring to the world.\\n\\nYour [specific quality or trait, e.g., kindness, creativity, hard work] truly makes a difference. I admire how you [specific action or achievement, e.g., tackle challenges, support others, inspire those around you]. It’s inspiring to see how you [mention a specific positive outcome or impact].\\n\\nRemember, every step you take, no matter how small, contributes to your journey and the lives of those around you. Keep shining your light and pursuing your passions!\\n\\nWishing you a wonderful day filled with joy and success!\\n\\nWarm regards,\\n\\n[Your Name]\\n\\n---\\n\\nFeel free to customize this template to suit your needs!'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"I ordered pizza for $9.99 and it was awesome!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "\u001b[1m> Entering new MultiPromptChain chain...\u001b[0m\n",
      "negative: {'input': 'What a nasty movie it was. Waste of time!'}\n",
      "\u001b[1m> Finished chain.\u001b[0m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'It seems like you\\'re looking for a \"negative template.\" Could you please clarify what context you need this template for? For example, are you looking for a negative feedback template, a rejection letter, or something else? This will help me assist you better!'"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain.run(\"What a nasty movie it was. Waste of time!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
