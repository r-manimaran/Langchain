{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade --quiet pinecone-client pinecone-text pinecone-notebooks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dotenv import load_dotenv, find_dotenv\n",
    "from langchain_community.retrievers import PineconeHybridSearchRetriever\n",
    "load_dotenv(find_dotenv())\n",
    "import os\n",
    "api_key = os.environ['PINECONE_API_KEY']\n",
    "#print(api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pinecone import Pinecone, ServerlessSpec\n",
    "index_name =\"hybrid-search-langchain-pinecone\"\n",
    "#initialize pinecone client\n",
    "pc = Pinecone(\n",
    "    api_key=api_key,\n",
    ")\n",
    "if index_name not in pc.list_indexes().names():\n",
    "    pc.create_index(\n",
    "        name=index_name,\n",
    "        dimension=384, # dimesnion of dense vector\n",
    "        metric=\"dotproduct\", ## sparse values supported only fo dotproduct\n",
    "        spec = ServerlessSpec(cloud='aws',region='us-east-1')\n",
    "        \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<pinecone.data.index.Index at 0x1b2e3d14c20>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = pc.Index(index_name)\n",
    "index "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 24.1.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain_huggingface\n",
      "  Downloading langchain_huggingface-0.0.3-py3-none-any.whl.metadata (1.2 kB)\n",
      "Collecting huggingface-hub>=0.23.0 (from langchain_huggingface)\n",
      "  Downloading huggingface_hub-0.23.5-py3-none-any.whl.metadata (12 kB)\n",
      "Requirement already satisfied: langchain-core<0.3,>=0.1.52 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langchain_huggingface) (0.2.20)\n",
      "Collecting sentence-transformers>=2.6.0 (from langchain_huggingface)\n",
      "  Using cached sentence_transformers-3.0.1-py3-none-any.whl.metadata (10 kB)\n",
      "Collecting tokenizers>=0.19.1 (from langchain_huggingface)\n",
      "  Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl.metadata (6.9 kB)\n",
      "Collecting transformers>=4.39.0 (from langchain_huggingface)\n",
      "  Using cached transformers-4.42.4-py3-none-any.whl.metadata (43 kB)\n",
      "Collecting filelock (from huggingface-hub>=0.23.0->langchain_huggingface)\n",
      "  Using cached filelock-3.15.4-py3-none-any.whl.metadata (2.9 kB)\n",
      "Collecting fsspec>=2023.5.0 (from huggingface-hub>=0.23.0->langchain_huggingface)\n",
      "  Using cached fsspec-2024.6.1-py3-none-any.whl.metadata (11 kB)\n",
      "Requirement already satisfied: packaging>=20.9 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (24.1)\n",
      "Requirement already satisfied: pyyaml>=5.1 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (6.0.1)\n",
      "Requirement already satisfied: requests in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (2.32.3)\n",
      "Requirement already satisfied: tqdm>=4.42.1 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.66.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from huggingface-hub>=0.23.0->langchain_huggingface) (4.12.2)\n",
      "Requirement already satisfied: jsonpatch<2.0,>=1.33 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (1.33)\n",
      "Requirement already satisfied: langsmith<0.2.0,>=0.1.75 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.1.88)\n",
      "Requirement already satisfied: pydantic<3,>=1 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.8.2)\n",
      "Requirement already satisfied: tenacity!=8.4.0,<9.0.0,>=8.1.0 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langchain-core<0.3,>=0.1.52->langchain_huggingface) (8.5.0)\n",
      "Collecting torch>=1.11.0 (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached torch-2.3.1-cp312-cp312-win_amd64.whl.metadata (26 kB)\n",
      "Requirement already satisfied: numpy in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from sentence-transformers>=2.6.0->langchain_huggingface) (1.26.4)\n",
      "Collecting scikit-learn (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl.metadata (12 kB)\n",
      "Collecting scipy (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl.metadata (60 kB)\n",
      "Collecting Pillow (from sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl.metadata (9.3 kB)\n",
      "Requirement already satisfied: regex!=2019.12.17 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from transformers>=4.39.0->langchain_huggingface) (2024.5.15)\n",
      "Collecting safetensors>=0.4.1 (from transformers>=4.39.0->langchain_huggingface)\n",
      "  Using cached safetensors-0.4.3-cp312-none-win_amd64.whl.metadata (3.9 kB)\n",
      "Requirement already satisfied: jsonpointer>=1.9 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from jsonpatch<2.0,>=1.33->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.0.0)\n",
      "Requirement already satisfied: orjson<4.0.0,>=3.9.14 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from langsmith<0.2.0,>=0.1.75->langchain-core<0.3,>=0.1.52->langchain_huggingface) (3.10.6)\n",
      "Requirement already satisfied: annotated-types>=0.4.0 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (0.7.0)\n",
      "Requirement already satisfied: pydantic-core==2.20.1 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from pydantic<3,>=1->langchain-core<0.3,>=0.1.52->langchain_huggingface) (2.20.1)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2.2.2)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from requests->huggingface-hub>=0.23.0->langchain_huggingface) (2024.7.4)\n",
      "Collecting sympy (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached sympy-1.13.0-py3-none-any.whl.metadata (12 kB)\n",
      "Collecting networkx (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached networkx-3.3-py3-none-any.whl.metadata (5.1 kB)\n",
      "Collecting jinja2 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached jinja2-3.1.4-py3-none-any.whl.metadata (2.6 kB)\n",
      "Collecting mkl<=2021.4.0,>=2021.1.1 (from torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.4 kB)\n",
      "Requirement already satisfied: colorama in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from tqdm>=4.42.1->huggingface-hub>=0.23.0->langchain_huggingface) (0.4.6)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\maran\\studymaterials\\git\\langchain\\rag-hybridsearch-pinecone\\venv\\lib\\site-packages (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface) (1.4.2)\n",
      "Collecting threadpoolctl>=3.1.0 (from scikit-learn->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached threadpoolctl-3.5.0-py3-none-any.whl.metadata (13 kB)\n",
      "Collecting intel-openmp==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl.metadata (1.2 kB)\n",
      "Collecting tbb==2021.* (from mkl<=2021.4.0,>=2021.1.1->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached tbb-2021.13.0-py3-none-win_amd64.whl.metadata (1.1 kB)\n",
      "Collecting MarkupSafe>=2.0 (from jinja2->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl.metadata (3.1 kB)\n",
      "Collecting mpmath<1.4,>=1.1.0 (from sympy->torch>=1.11.0->sentence-transformers>=2.6.0->langchain_huggingface)\n",
      "  Using cached mpmath-1.3.0-py3-none-any.whl.metadata (8.6 kB)\n",
      "Downloading langchain_huggingface-0.0.3-py3-none-any.whl (17 kB)\n",
      "Downloading huggingface_hub-0.23.5-py3-none-any.whl (402 kB)\n",
      "   ---------------------------------------- 0.0/402.8 kB ? eta -:--:--\n",
      "   --- ----------------------------------- 41.0/402.8 kB 991.0 kB/s eta 0:00:01\n",
      "   ----------- ---------------------------- 112.6/402.8 kB 1.6 MB/s eta 0:00:01\n",
      "   ---------------- ----------------------- 163.8/402.8 kB 1.4 MB/s eta 0:00:01\n",
      "   -------------------------------- ------- 327.7/402.8 kB 2.0 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/402.8 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------  399.4/402.8 kB 2.1 MB/s eta 0:00:01\n",
      "   ---------------------------------------- 402.8/402.8 kB 1.5 MB/s eta 0:00:00\n",
      "Using cached sentence_transformers-3.0.1-py3-none-any.whl (227 kB)\n",
      "Using cached tokenizers-0.19.1-cp312-none-win_amd64.whl (2.2 MB)\n",
      "Using cached transformers-4.42.4-py3-none-any.whl (9.3 MB)\n",
      "Using cached fsspec-2024.6.1-py3-none-any.whl (177 kB)\n",
      "Using cached safetensors-0.4.3-cp312-none-win_amd64.whl (289 kB)\n",
      "Using cached torch-2.3.1-cp312-cp312-win_amd64.whl (159.7 MB)\n",
      "Using cached filelock-3.15.4-py3-none-any.whl (16 kB)\n",
      "Using cached pillow-10.4.0-cp312-cp312-win_amd64.whl (2.6 MB)\n",
      "Using cached scikit_learn-1.5.1-cp312-cp312-win_amd64.whl (10.9 MB)\n",
      "Using cached scipy-1.14.0-cp312-cp312-win_amd64.whl (44.5 MB)\n",
      "Using cached mkl-2021.4.0-py2.py3-none-win_amd64.whl (228.5 MB)\n",
      "Using cached intel_openmp-2021.4.0-py2.py3-none-win_amd64.whl (3.5 MB)\n",
      "Using cached tbb-2021.13.0-py3-none-win_amd64.whl (286 kB)\n",
      "Using cached threadpoolctl-3.5.0-py3-none-any.whl (18 kB)\n",
      "Using cached jinja2-3.1.4-py3-none-any.whl (133 kB)\n",
      "Using cached networkx-3.3-py3-none-any.whl (1.7 MB)\n",
      "Using cached sympy-1.13.0-py3-none-any.whl (6.2 MB)\n",
      "Using cached MarkupSafe-2.1.5-cp312-cp312-win_amd64.whl (17 kB)\n",
      "Using cached mpmath-1.3.0-py3-none-any.whl (536 kB)\n",
      "Installing collected packages: tbb, mpmath, intel-openmp, threadpoolctl, sympy, scipy, safetensors, Pillow, networkx, mkl, MarkupSafe, fsspec, filelock, scikit-learn, jinja2, huggingface-hub, torch, tokenizers, transformers, sentence-transformers, langchain_huggingface\n",
      "Successfully installed MarkupSafe-2.1.5 Pillow-10.4.0 filelock-3.15.4 fsspec-2024.6.1 huggingface-hub-0.23.5 intel-openmp-2021.4.0 jinja2-3.1.4 langchain_huggingface-0.0.3 mkl-2021.4.0 mpmath-1.3.0 networkx-3.3 safetensors-0.4.3 scikit-learn-1.5.1 scipy-1.14.0 sentence-transformers-3.0.1 sympy-1.13.0 tbb-2021.13.0 threadpoolctl-3.5.0 tokenizers-0.19.1 torch-2.3.1 transformers-4.42.4\n"
     ]
    }
   ],
   "source": [
    "!pip install langchain_huggingface"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_huggingface import HuggingFaceEmbeddings\n",
    "embeddings = HuggingFaceEmbeddings(\n",
    "    model_name=\"sentence-transformers/all-MiniLM-L6-v2\"\n",
    ")\n",
    "embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Darshan\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<pinecone_text.sparse.bm25_encoder.BM25Encoder at 0x1b281486e40>"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pinecone_text.sparse import BM25Encoder\n",
    "bm25_encoder = BM25Encoder().default()\n",
    "bm25_encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:00<00:00, 11.35it/s]\n"
     ]
    }
   ],
   "source": [
    "sentences = [\n",
    "    \"In 2023, I visited London\",\n",
    "    \"In 2022, I visited India\",\n",
    "    \"In 2021, I visited Connecticut\"\n",
    "]\n",
    "\n",
    "bm25_encoder.fit(sentences)\n",
    "\n",
    "#store the values to json file\n",
    "bm25_encoder.dump(\"bm25_encoder.json\")\n",
    "\n",
    "#load the BM25 encoder from json file\n",
    "bm25_encoder = BM25Encoder().load(\"bm25_encoder.json\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PineconeHybridSearchRetriever(embeddings=HuggingFaceEmbeddings(client=SentenceTransformer(\n",
       "  (0): Transformer({'max_seq_length': 256, 'do_lower_case': False}) with Transformer model: BertModel \n",
       "  (1): Pooling({'word_embedding_dimension': 384, 'pooling_mode_cls_token': False, 'pooling_mode_mean_tokens': True, 'pooling_mode_max_tokens': False, 'pooling_mode_mean_sqrt_len_tokens': False, 'pooling_mode_weightedmean_tokens': False, 'pooling_mode_lasttoken': False, 'include_prompt': True})\n",
       "  (2): Normalize()\n",
       "), model_name='sentence-transformers/all-MiniLM-L6-v2', cache_folder=None, model_kwargs={}, encode_kwargs={}, multi_process=False, show_progress=False), sparse_encoder=<pinecone_text.sparse.bm25_encoder.BM25Encoder object at 0x000001B282B0F3B0>, index=<pinecone.data.index.Index object at 0x000001B2E3D14C20>)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever = PineconeHybridSearchRetriever(\n",
    "    embeddings=embeddings,\n",
    "    sparse_encoder= bm25_encoder,\n",
    "    index= index\n",
    ")\n",
    "retriever"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 1/1 [00:10<00:00, 10.82s/it]\n"
     ]
    }
   ],
   "source": [
    "retriever.add_texts(\n",
    "    [\n",
    "    \"In 2023, I visited London\",\n",
    "    \"In 2022, I visited India\",\n",
    "    \"In 2021, I visited Connecticut\"\n",
    "]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(page_content='In 2021, I visited Connecticut'),\n",
       " Document(page_content='In 2023, I visited London'),\n",
       " Document(page_content='In 2022, I visited India')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "retriever.invoke(\"what city did i visit last?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
